#################################################################################################################################################################
# Remarks:     06/29/21: history19s.ps1 launches probing query every 50 iterations and at beginning of script to adjust timers.
#              Script to export data from Log Analytics to Blob Storage. Added suport for blob tags on 06/24/21.
#                          #
#              v12+ adding user input in function. Added ability to increment queries to avoid memory limitations and timeout.
#              This version requests user input for a given Log Analytic table name. It queries the LA table based on specified time period.  
#              
# 
# Conact: ronaldon2023@gmail.com
###################################################################################################################################################################

PARAM(             
    [Parameter(Mandatory=$false)] $AccessPolicyName="RootManageSharedAccessKey",
    [Parameter(Mandatory=$false)] $Access_Policy_Key="default=",    
    [Parameter(Mandatory=$false)] $INCR=5,
    $nugetPackageLocation = "$($env:USERPROFILE)\.nuget\packages", #global-packages", # local
    $nugetIndex = "https://api.nuget.org/v3/index.json",
    $nugetDownloadUrl = "https://dist.nuget.org/win-x86-commandline/latest/nuget.exe",
    $kustoToolsPackage = "microsoft.azure.kusto.tools",
    $maxfilesize = 1024  * 1024 * 1024 * 3.6,
    $currentfilesize = 0,
    $SASTokenStorage = "",
    $StartDate,
    $EndDate,
    $Blob,
    $Table,
    $LAWID
 )

$location = Get-Location 

IF ($location -like "*C:\*") 
{
    Write-Warning "Please execute script only from storage disks. This seems to be the operating system disk. $location"
    Break
} 

$isroot = Split-Path -Path (Get-Location) -Parent
If ($isroot -ne "") 
{
    Write-Warning "You may be inside a folder. Please execute script from the root."
    Break
}  

$folderpath = "$($location)export_"
$logpath = "$($location)logging_\log.txt"
$folder_for_output = "$($location)export_"
Write-Host "Files will be created under a folder drive:/export_" -ForegroundColor DarkGreen
Write-Host $folderpath -ForegroundColor DarkGreen

If ( -Not (test-path $folderpath)) 
{
    New-Item -Path $folderpath -ItemType Directory 
}

If ( -Not (test-path "$($location)logging_")) 
{
    New-Item -Path "$($location)logging_" -ItemType Directory 
}

function get-SAStoken{

    Param(
        $EventHubNamespace,
        $EventHub,
        $Access_Policy_Name,
        $Access_Policy_Key
    )
    [Reflection.Assembly]::LoadWithPartialName("System.Web")| out-null
    $URI="$($EventHubNamespace).servicebus.windows.net/$($EventHub)"
    #Token expires now+3000000
    $Expires=([DateTimeOffset]::Now.ToUnixTimeSeconds())+3000000
    $SignatureString=[System.Web.HttpUtility]::UrlEncode($URI)+ "`n" + [string]$Expires
    $HMAC = New-Object System.Security.Cryptography.HMACSHA256
    $HMAC.key = [Text.Encoding]::ASCII.GetBytes($Access_Policy_Key)
    $Signature = $HMAC.ComputeHash([Text.Encoding]::ASCII.GetBytes($SignatureString))
    $Signature = [Convert]::ToBase64String($Signature)
    $SASToken = "SharedAccessSignature sr=" + [System.Web.HttpUtility]::UrlEncode($URI) + "&sig=" + [System.Web.HttpUtility]::UrlEncode($Signature) + "&se=" + $Expires + "&skn=" + $Access_Policy_Name
    
    return $SASToken

}
function QueryLogAnalyticsSend {  
        Param(
        $TableName, 
        $startperiod, 
        $endperiod, 
        $LogAnalyticsWorkspaceId,
        $statusjson,
        $fc,
        $filename,
        $blobsas
        )
        
        $filecount = $fc
        $query = "$($TableName)| where TimeGenerated >= datetime($startperiod) and TimeGenerated <= datetime($endperiod)"
        Write-Host "$query" -ForegroundColor Cyan
        $query | Out-File $logpath -Append

        Try 
        {
            $output = (Invoke-AzOperationalInsightsQuery -WorkspaceId $LogAnalyticsWorkspaceId -Query $query).Results
        }

        Catch 
        {
            write-Error "Error : $_.ErrorDetails.Message"
            write-Error "Command : $_.InvocationInfo.Line"
            Write-Host "Resend:$query"
            $query | Out-File $logpath -Append
            "Error : $_.ErrorDetails.Message" | Out-File $logpath -Append
        }
          
        $irow = 0    
        $arrayrows = @() 
        $gettimestamp = @()
        $getlogprefix = $TableName.Substring(0,3)+$LogAnalyticsWorkspaceId.Substring(0,3)
        $getperiod = $filename.Replace(" ","T").Replace(":","_")
        $getperiod = $getlogprefix+$getperiod
        
        $converted_output = $output | ConvertTo-Json
        IF ($NULL -ne $converted_output) 
        {    
    
             foreach ($row in $output) 
                {
                    IF ($irow -eq 0) 
                    {
                        $rowtimestamp = $row.'TimeGenerated'
                        $gettimestamp = $gettimestamp + $rowtimestamp    
                    }                    
                    $irow++
                    $row_json = $row | ConvertTo-Json -Compress -Depth 20
                    
                    $arrayrows = $arrayrows + $row_json
                }   
                Write-Host "Total of rows for this query:$irow" -ForegroundColor DarkGreen
                $body_join = $arrayrows -join ","
                #$folder_for_output = "K:\export_"
                if($filecount -eq 0){
                   
                    Write-Host "Creating new file..."
                    $filecount++
                  
                    saveToFile -output "{`"records`":[" -filepath "$($folder_for_output)\$($getperiod)_$($filecount).json"
                    saveToFile -output $body_join -filepath "$($folder_for_output)\$($getperiod)_$($filecount).json"
                }
                else
                {
                    $filedisksize = Get-Childitem -file "$($folder_for_output)\$($getperiod)_$filecount.json" | Select-Object length
                    $resultsize = [System.Text.Encoding]::UTF8.GetByteCount($body_join)

                    #check if file size + body > max allowed size
                    $mymax = "3821223823"
                    Write-Host "File size will be:$filedisksize.Length+$resultsize"
                                        
                    #if($filedisksize.Length+$resultsize -gt $global:maxfilesize){
                     if($filedisksize.Length+$resultsize -gt $mymax){
                        Write-Host "Number of rows processed:$irow"
                        saveToFile -output "]}" -filepath "$($folder_for_output)\$($getperiod)_$($filecount).json"
                        $rowtimestampend = $row.'TimeGenerated'
                        $gettimestamp = $gettimestamp + $rowtimestampend

                        $status = UploadToBlob -TableName $TableName -blobsas $blobsas -tagtimestamp $gettimestamp -filetoupload "$($folder_for_output)\$($getperiod)_$($filecount).json" 
                        IF ($status)
                        {
                            Remove-Item -Path "$($folder_for_output)\$($getperiod)_$($filecount).json"
                        }
                        else 
                        {
                            Write-Warning "File $($folder_for_output)\$($getperiod)_$($filecount) not uploaded! File in disk."
                        }
                        $filecount++
                      
                        saveToFile -output "{`"records`":[" -filepath "$($folder_for_output)\$($getperiod)_$($filecount).json"
                        saveToFile -output $body_join -filepath "$($folder_for_output)\$($getperiod)_$($filecount).json"
                    }
                    else{
                        #append to $filecount.json
                        saveToFile -output "," -filepath "$($folder_for_output)\$($getperiod)_$($filecount).json"
                        saveToFile -output $body_join -filepath "$($folder_for_output)\$($getperiod)_$($filecount).json"
                        "Saving to file..." | Out-File $logpath -Append

                    }
                    }
                    if($statusjson -eq "end"){
                        $rowtimestampend = $row.'TimeGenerated'
                        $gettimestamp = $gettimestamp + $rowtimestampend
                        saveToFile -output "]}" -filepath "$($folder_for_output)\$($getperiod)_$($filecount).json"
                        $status = UploadToBlob -TableName $TableName -blobsas $blobsas -tagtimestamp $gettimestamp -filetoupload "$($folder_for_output)\$($getperiod)_$($filecount).json"
                        IF ($status)
                        {
                            Remove-Item -Path "$($folder_for_output)\$($getperiod)_$($filecount).json"
                        }
                        else 
                        {
                            Write-Warning "$($folder_for_output)\$($getperiod)_$($filecount).json"
                        }
                    }   
            }  
        else 
        {   
            Write-Host "No data."                     
        }
    return $filecount 
}
function GetUserInputObj 
{
    $LogAnalyticsWorkspaceId = $LAWID
    IF ($null -eq $LAWID)
    {
        $templa_default = "5dd67a86-09ea-4310-bf07-99c209a19ec1"
        If (!($value = Read-Host "LA WorkspaceId[$templa_default]")) { $value = $templa_default} 
        $LogAnalyticsWorkspaceId = $value
    }
    $blobsas = $Blob
    IF ($null -eq $Blob)
    {
        $blobsas = Read-Host -Prompt "Blob SAS Token URL" 
    }
    $TableName = $Table
    IF ($null -eq $Table)
    { 
        $TableName   = Read-Host -Prompt "Log Analytics Table (CASE SENSITIVE)"  
    }
    $startperiod = $StartDate
    IF ($null -eq $StartDate)
    { 
        $startperiod = Read-Host -Prompt "Log export start date YYYY-MM-DD HH:MM:SS"
    }

    $endperiod = $EndDate
        IF ($null -eq $EndDate) 
    {
        $endperiod   = Read-Host -Prompt "Log export end   date YYYY-MM-DD HH:MM:SS"
    }

    $value = @{}    
    #Build Blob container URI for AzCopy
    $blobcontainer = $TableName.ToLower()+"history"
    $blobsas = $blobsas.Replace(".net",".net/$blobcontainer")
    $value.LogAnalyticsWorkspaceId = $LogAnalyticsWorkspaceId
    $value.TableName = $TableName
    $value.startperiod = $startperiod
    $value.endperiod = $endperiod
    $value.blobsas = $blobsas
    $valueObj = (New-Object PSObject -Property $value)
    "-Printing start, end, LA ID----------------------------------" | Out-File $logpath -Append
    $startperiod+" "+$endperiod + " " + $LogAnalyticsWorkspaceId    | Out-File $logpath -Append
    "-end---------------------------------------------------------" | Out-File $logpath -Append
    return $valueObj
}
function saveToFile 
{  
      PARAM(
            $output,
            $filepath
            )    
    Try
    {
       
        Write-Host "Writing to file..."
        Write-Host "$($filepath)" -ForegroundColor Green
        $output  | Out-File  "$($filepath)" -Append

    }
    Catch
    {
        Write-Error "Error saving to file"
        Write-Error "Error : $_.ErrorDetails.Message"
        Write-Error "Command : $_.InvocationInfo.Line"
    }
    
    return $updatedfile
}

function UploadToBlob
{
       PARAM( 
              $blobsas,
              $filetoupload,
              $TableName,
              $tagtimestamp
             )
        $starttag = $tagtimestamp[0]
        $tagbuilder = "startdate=$starttag&"
        $tagbuilder = $tagbuilder+"enddate="+$tagtimestamp[$tagtimestamp.length-1]
              
        Write-Host "Uploading to blob storage... $($filetoupload)" -ForegroundColor Green
       
        $status = ""      
        #Call AzCopy 
        Try 
        {      
            $status = & 'K:\azcopy.exe' copy $filetoupload $blobsas --blob-tags=$tagbuilder                          
        }
        Catch 
        {
            Write-Warning "Error executing Azcopy!
            "Error during AzCopy $status" | Out-File $logpath -Append
            write-Error "Error : $_.ErrorDetails.Message"
            write-Error "Command : $_.InvocationInfo.Line"
            return $false
        }

        IF ($status -contains "Number of Transfers Failed: 0"){
            Write-Host "Successfully transferred file $filetoupload" -ForegroundColor Yellow
            "Successfully transferred file $filetoupload" | Out-File $logpath -Append
        }
        else{
            Write-Host $status -ForegroundColor Cyan
            Write-Warning "Error uploading to AzCopy!"
            "Error : $_.ErrorDetails.Message" | Out-File $logpath -Append
            return $false
        }

        return $true
        
}

function GetSampleQuery 
{
    Param
    (
    $LogAnalyticsWorkspaceID,
    $TableName,
    $startperiod
    )
        $increment = 1
        $StartDate = Get-Date $startperiod 
        $StartDateString = $StartDate.ToString("yyyy-MM-dd HH:mm:ss.fffff")
        $samplestartperiod = $StartDate
        $sampleendperiod = $StartDate.AddSeconds(1)
        $EndDateString = $sampleendperiod.ToString("yyyy-MM-dd HH:mm:ss.fffff")
        $samplequery = "$($TableName)| where TimeGenerated >= datetime($StartDateString) and TimeGenerated <= datetime($EndDateString)"

        Write-Host "Executing sample query to determine optimal query increment time..." -ForeGroundColor DarkYellow
        Write-Host $samplequery -ForeGroundColor Gray
        #$samplequery | Out-File $logpath -Append

        Try 
        {

            $sampleoutput= (Invoke-AzOperationalInsightsQuery -WorkspaceId $LogAnalyticsWorkspaceId -Query $samplequery).Results
        }

        Catch {
            write-Error "Error : $_.ErrorDetails.Message"
            write-Error "Command : $_.InvocationInfo.Line"
            Write-Host "Resend:$query"
            "Error : $_.ErrorDetails.Message" | Out-File $logpath -Append

        }

    $converted_out_json = $sampleoutput | ConvertTo-Json
    #IF ( ($null -eq $sampleoutput) -and ( $sampleoutput.count -le 0)) 
    IF ($NULL -eq $converted_out_json)
    {   
            Write-Host "No data..."
            $increment = 1
            
    }
    else
    {
    
        $checksampleoutsize =  [System.Text.Encoding]::UTF8.GetByteCount($converted_out_json)
        $size =  $checksampleoutsize  
        IF ($size -ge 40671990) 
        { 
            $increment = 0.5
            Write-Host "This appears to be a high density table.~72h to process 1/4 day history logs.
        }
        elseif ($size -lt 69990) 
        {
          $increment = 300
          Write-Host "This appears to be a sparse table.~8h to process 1 day history logs."
        }
        elseif ($size -lt 10671990)
        {
          $increment = 03
          Write-Host "This appears to be a medium-sparse table.~18h to process 1 day history logs."
     
        }
    }
    return $increment
    
}

<##############
      MAIN()
###############>

$v = GetUserInputObj

$LogAnalyticsWorkspaceId = $v.LogAnalyticsWorkspaceId.Trim() 
#$SASTokenStorageAccount = $v.SASTokenStorageAccount.Trim()
$TableName = $v.TableName.Trim()
$startperiod = $v.startperiod.Trim()
$endperiod = $v.endperiod.Trim()
$blobsas   = $v.blobsas
#$SASTokenStorage = $v.SASTokenStorage.Trim()

$StartDate = Get-Date $startperiod
$EndDate =   Get-Date $endperiod
$currentDate = $StartDate

$MinuteInterval = 2
$iloop = 0

"$($location)export_$($date)\"

#Iterate in small period increments to avoid timeouts and max query size limits against Log Analytics:
$filecount = 0
    DO
      {
        $statusjson = "progress"
      
        IF ($iloop -gt 0) 
        {        
            $StartDateString = $currentDate.ToString("yyyy-MM-dd HH:mm:ss.fffff")+"1"

        } else {
            
            $StartDateString = $currentDate.ToString("yyyy-MM-dd HH:mm:ss.ffffff")
            $intincr = 1
        }
      
        IF ($iloop % 50 -eq 0) 
        { 
            $incremental = GetSampleQuery -LogAnalyticsWorkspaceId $LogAnalyticsWorkspaceId -TableName $TableName -startperiod $startperiod
            $intincr = $incremental[-1]
            Write-Host "Sample query performed... incremental is $intincr"
        }

        $currentDate = $currentDate.AddSeconds($intincr)
        IF ($currentDate -gt $EndDate) 
        {
            $currentDate = $EndDate
        }
        $EndDateString = $currentDate.ToString("yyyy-MM-dd HH:mm:ss.ffffff")
        
        $LAstart = $StartDateString
        $LAend   = $EndDateString 
        IF ($currentdate -eq $EndDate)
        {

            $statusjson = "end"
        }
        elseif ($currentdate -eq $startdate) 
        {
            $statusjson = "begin"
        }       
        
        $count = QueryLogAnalyticsSend -TableName $TableName -startperiod  $LAstart -endperiod $LAend -LogAnalyticsWorkspaceId $LogAnalyticsWorkspaceId -statusjson $statusjson -fc $filecount -filename $startperiod -blobsas $blobsas
        $filecount = $count[-1]
      
        $iloop++
                     
     } While ($currentDate -ne $EndDate)

Write-Host "** Normal end"
"Completed queries:$iloop" | Out-File $logpath -Append
$completiontime = Get-Date 
Write-Host $completiontime
